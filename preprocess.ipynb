{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/g6FWVnlC2VQY9SpiQEZy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwarya-walimbe/Fraud-Detetection-Using-GNN/blob/main/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ss65colp7E",
        "outputId": "f37dd891-0976-40fa-dd19-b51e1354dcf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cur_path = \"/content/drive/MyDrive/Fraud_Detection_Project/\"\n",
        "os.chdir(cur_path)\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfledaXkmH1-",
        "outputId": "e766ba68-3df5-49bb-9843-7a329e4612cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fraud_Detection_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeJ-7OEyl12R",
        "outputId": "233f1ef5-6a24-41e0-a4fc-0b0bc5792b69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Fraud_Detection_Project/paysim.csv\""
      ],
      "metadata": {
        "id": "2-K_DMoGm0a6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path: str, sample_size: int = 200_000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Stratified sample: keep ALL fraud rows, fill rest with normal rows.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    fraud_df    = df[df[\"isFraud\"] == 1]\n",
        "    nonfraud_df = df[df[\"isFraud\"] == 0].sample(\n",
        "        n=sample_size - len(fraud_df), random_state=42\n",
        "    )\n",
        "\n",
        "    df_small = pd.concat([fraud_df, nonfraud_df]).reset_index(drop=True)\n",
        "    print(f\"[load_data] rows={len(df_small):,}  fraud={fraud_df.shape[0]:,}  \"\n",
        "          f\"({fraud_df.shape[0]/len(df_small)*100:.2f}%)\")\n",
        "    return df_small\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3hgWY_SvmxhN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_graph(df: pd.DataFrame) -> Data:\n",
        "\n",
        "    # ── 2a. Account → integer ID ──────────────────────────────\n",
        "    all_accounts = pd.concat([df[\"nameOrig\"], df[\"nameDest\"]]).unique()\n",
        "    account2id   = {acc: i for i, acc in enumerate(all_accounts)}\n",
        "    num_nodes    = len(account2id)\n",
        "\n",
        "    # ── 2b. Encode transaction type ───────────────────────────\n",
        "    type_map = {t: i for i, t in enumerate(df[\"type\"].unique())}\n",
        "    df = df.copy()\n",
        "    df[\"type_enc\"] = df[\"type\"].map(type_map)\n",
        "\n",
        "    # Extract hour from 'step' column (step ≈ hours since simulation start)\n",
        "    df[\"hour\"] = df[\"step\"] % 24\n",
        "\n",
        "    # ── 2c. Build edge_index + edge_attr ─────────────────────\n",
        "    src_ids = df[\"nameOrig\"].map(account2id).values\n",
        "    dst_ids = df[\"nameDest\"].map(account2id).values\n",
        "\n",
        "    edge_index = torch.tensor(\n",
        "        np.vstack([src_ids, dst_ids]), dtype=torch.long\n",
        "    )\n",
        "\n",
        "    # Edge features: [amount, type_enc, hour, oldbalanceOrg, newbalanceOrig]\n",
        "    edge_attr_raw = df[\n",
        "        [\"amount\", \"type_enc\", \"hour\", \"oldbalanceOrg\", \"newbalanceOrig\"]\n",
        "    ].values.astype(np.float32)\n",
        "\n",
        "    scaler_edge  = StandardScaler()\n",
        "    edge_attr_sc = scaler_edge.fit_transform(edge_attr_raw)\n",
        "    edge_attr    = torch.tensor(edge_attr_sc, dtype=torch.float)\n",
        "\n",
        "\n",
        "    nf = np.zeros((num_nodes, 12), dtype=np.float64)\n",
        "    unique_dest = [set() for _ in range(num_nodes)]\n",
        "    unique_src  = [set() for _ in range(num_nodes)]\n",
        "\n",
        "    for row in df.itertuples(index=False):\n",
        "        s   = account2id[row.nameOrig]\n",
        "        d   = account2id[row.nameDest]\n",
        "        amt = row.amount\n",
        "\n",
        "        # Sent-side\n",
        "        nf[s, 0] += amt\n",
        "        nf[s, 2] += 1\n",
        "        nf[s, 6]  = max(nf[s, 6], amt)\n",
        "        nf[s, 8] += max(0, row.oldbalanceOrg - row.newbalanceOrig)\n",
        "        unique_dest[s].add(d)\n",
        "\n",
        "        # Received-side\n",
        "        nf[d, 1] += amt\n",
        "        nf[d, 3] += 1\n",
        "        nf[d, 7]  = max(nf[d, 7], amt)\n",
        "        nf[d, 9] += max(0, row.oldbalanceDest - row.newbalanceDest) \\\n",
        "                    if hasattr(row, \"oldbalanceDest\") else 0\n",
        "        unique_src[d].add(s)\n",
        "\n",
        "    # Averages\n",
        "    nf[:, 4] = np.divide(nf[:, 0], nf[:, 2],\n",
        "                         out=np.zeros(num_nodes), where=nf[:, 2] != 0)\n",
        "    nf[:, 5] = np.divide(nf[:, 1], nf[:, 3],\n",
        "                         out=np.zeros(num_nodes), where=nf[:, 3] != 0)\n",
        "\n",
        "    # Unique counterparty counts\n",
        "    nf[:, 10] = np.array([len(s) for s in unique_dest])\n",
        "    nf[:, 11] = np.array([len(s) for s in unique_src])\n",
        "\n",
        "    scaler_node = StandardScaler()\n",
        "    nf_scaled   = scaler_node.fit_transform(nf)\n",
        "\n",
        "    # Guard against NaN / Inf after scaling\n",
        "    nf_scaled = np.nan_to_num(nf_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    x = torch.tensor(nf_scaled, dtype=torch.float)\n",
        "\n",
        "    # ── 2e. Labels ────────────────────────────────────────────\n",
        "    labels = np.zeros(num_nodes, dtype=np.int64)\n",
        "    for row in df.itertuples(index=False):\n",
        "        if row.isFraud == 1:\n",
        "            labels[account2id[row.nameOrig]] = 1\n",
        "\n",
        "    y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    # ── 2f. 3-way split: 70% train / 10% val / 20% test ──────\n",
        "    idx            = torch.arange(num_nodes)\n",
        "    train_idx, tmp = train_test_split(idx, test_size=0.30,\n",
        "                                      stratify=y.numpy(), random_state=42)\n",
        "    val_idx, test_idx = train_test_split(tmp, test_size=0.667,\n",
        "                                          stratify=y[tmp].numpy(),\n",
        "                                          random_state=42)\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask   = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[val_idx]     = True\n",
        "    test_mask[test_idx]   = True\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask   = val_mask\n",
        "    data.test_mask  = test_mask\n",
        "\n",
        "    print(f\"[build_graph] nodes={num_nodes:,}  edges={edge_index.shape[1]:,}  \"\n",
        "          f\"fraud_nodes={int(y.sum()):,}\")\n",
        "    print(f\"  train={int(train_mask.sum()):,}  \"\n",
        "          f\"val={int(val_mask.sum()):,}  \"\n",
        "          f\"test={int(test_mask.sum()):,}\")\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "RLaiPVh9nfZV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dprVVq8LW_Y9"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}