{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr/1cY/TiakV3ius+JU5+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwarya-walimbe/Fraud-Detetection-Using-GNN/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQOYSi4eomk3",
        "outputId": "08e6c719-7ae2-4b9a-863e-7860bce0b1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cur_path = '/content/drive/MyDrive/Fraud_Detection_Project'\n",
        "os.chdir(cur_path)\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Obv4Ydnow8Q",
        "outputId": "4548c2e3-837c-480c-9890-3e7e963d839c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fraud_Detection_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run preprocess.ipynb\n",
        "%run model.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU-EL1w0pPi8",
        "outputId": "4f3be047-5423-4fe4-a8f1-39bf1f4637b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Fraud_Detection_Project\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Fraud_Detection_Project\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "ImprovedGraphSAGE: ImprovedGraphSAGE(\n",
            "  (conv1): SAGEConv(12, 128, aggr=mean)\n",
            "  (conv2): SAGEConv(128, 128, aggr=mean)\n",
            "  (conv3): SAGEConv(128, 128, aggr=mean)\n",
            "  (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (skip): Linear(in_features=12, out_features=128, bias=False)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "GATFraudNet:       GATFraudNet(\n",
            "  (conv1): GATConv(12, 64, heads=4)\n",
            "  (conv2): GATConv(256, 64, heads=1)\n",
            "  (bn1): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "metadata": {
        "id": "1WW3WNNfpich"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# The functions and classes from preprocess.ipynb and model.ipynb should be available\n",
        "# in the global namespace after the `%run` commands in the previous cell.\n",
        "# Therefore, explicit imports are not needed and cause a ModuleNotFoundError.\n",
        "\n",
        "os.makedirs(\"outputs\", exist_ok=True)"
      ],
      "metadata": {
        "id": "iSJM7IOOYqUs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Fraud_Detection_Project/paysim.csv\""
      ],
      "metadata": {
        "id": "UupdUBFWpsza"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_data(file_path)\n",
        "data = build_graph(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0JxQUI70MXO",
        "outputId": "7d0ecf8d-f98f-49c1-8e54-e380d8f5bd0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_data] rows=200,000  fraud=8,213  (4.11%)\n",
            "[build_graph] nodes=374,979  edges=200,000  fraud_nodes=8,213\n",
            "  train=262,485  val=37,460  test=75,034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss (Lin et al., 2017).\n",
        "\n",
        "    Why better than plain cross-entropy for fraud?\n",
        "    The dataset is ~98% non-fraud. With plain loss the model\n",
        "    gets away with memorising \"everything is normal.\"\n",
        "\n",
        "    Focal loss DOWN-WEIGHTS the loss on easy (confident) examples\n",
        "    and UP-WEIGHTS the loss on hard (uncertain) examples —\n",
        "    forcing the model to focus on the rare fraud cases.\n",
        "\n",
        "    gamma=2 is the standard starting point.\n",
        "    alpha weights the positive (fraud) class higher.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction=\"none\")\n",
        "        pt      = torch.exp(-ce_loss)                          # probability of correct class\n",
        "        focal   = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal.mean()"
      ],
      "metadata": {
        "id": "q6ANBceo57xV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THRESHOLD TUNING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "def find_best_threshold(probs: np.ndarray, labels: np.ndarray,\n",
        "                        step: float = 0.01) -> tuple[float, float]:\n",
        "    \"\"\"Scan thresholds on validation set, return (best_threshold, best_f1).\"\"\"\n",
        "    best_t, best_f1 = 0.5, 0.0\n",
        "    for t in np.arange(0.1, 0.95, step):\n",
        "        preds = (probs >= t).astype(int)\n",
        "        f1    = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_t = f1, t\n",
        "    return best_t, best_f1"
      ],
      "metadata": {
        "id": "I5SrXbEe6Jf4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "def evaluate(model, data, mask, threshold: float = 0.5) -> dict:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits  = model(data)\n",
        "        probs   = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "        labels  = data.y[mask].cpu().numpy()\n",
        "        mask_np = mask.cpu().numpy()\n",
        "        preds   = (probs[mask_np] >= threshold).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"probs\":  probs[mask_np],\n",
        "        \"labels\": labels,\n",
        "        \"preds\":  preds,\n",
        "        \"f1\":     f1_score(labels, preds, zero_division=0),\n",
        "        \"auc\":    roc_auc_score(labels, probs[mask_np]),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "MMW7EtRX7_nM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Model selection ───────────────────────────────────────\n",
        "\n",
        "# Define model parameters\n",
        "use_gat = False # Set to True to use GATFraudNet, False for ImprovedGraphSAGE\n",
        "hidden = 64 # Number of hidden units\n",
        "lr = 0.001 # Learning rate\n",
        "epochs = 100 # Number of training epochs\n",
        "patience = 20 # Early stopping patience\n",
        "\n",
        "print(f\"[config] use_gat={use_gat}, hidden={hidden}, lr={lr}, epochs={epochs}, patience={patience}\")\n",
        "\n",
        "\n",
        "if use_gat:\n",
        "    edge_dim = data.edge_attr.shape[1] if hasattr(data, \"edge_attr\") else 5\n",
        "    model    = GATFraudNet(in_channels=data.num_features,\n",
        "                           hidden_channels=hidden,\n",
        "                           heads=4, edge_dim=edge_dim)\n",
        "    print(f\"[train] Using GATFraudNet  | features={data.num_features} | \"\n",
        "          f\"hidden={hidden} | edge_dim={edge_dim}\")\n",
        "else:\n",
        "    model = ImprovedGraphSAGE(in_channels=data.num_features,\n",
        "                              hidden_channels=hidden)\n",
        "    print(f\"[train] Using ImprovedGraphSAGE | features={data.num_features} | \"\n",
        "          f\"hidden={hidden}\")\n",
        "\n",
        "# ── Focal loss (replaces plain NLLLoss) ───────────────────\n",
        "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "\n",
        "# ── Optimiser + LR scheduler ──────────────────────────────\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,\n",
        "                              weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", factor=0.5, patience=10\n",
        ")\n",
        "\n",
        "# ── Training loop ─────────────────────────────────────────\n",
        "train_losses, val_f1s   = [], []\n",
        "best_val_f1, best_epoch = 0.0, 0\n",
        "patience_counter        = 0\n",
        "best_state              = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # --- Forward + loss ---\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(data)\n",
        "    loss   = criterion(logits[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # gradient clipping\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # --- Validation F1 every epoch ---\n",
        "    result = evaluate(model, data, data.val_mask, threshold=0.5)\n",
        "    val_f1 = result[\"f1\"]\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | \"\n",
        "              f\"Val F1: {val_f1:.4f} | LR: {optimizer.param_groups[0][\"lr\"]:.5f}\")\n",
        "\n",
        "    # --- Early stopping ---\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1   = val_f1\n",
        "        best_epoch    = epoch\n",
        "        best_state    = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n[early stop] No improvement for {patience} epochs. \"\n",
        "                  f\"Best Val F1={best_val_f1:.4f} at epoch {best_epoch}\")\n",
        "            break\n",
        "\n",
        "# ── Restore best weights\n",
        "if best_state:\n",
        "    model.load_state_dict(best_state)\n",
        "    print(f\"[train] Restored best model from epoch {best_epoch}\")\n",
        "\n",
        "plot_loss_curve(train_losses, val_f1s)\n",
        "\n",
        "# ── Tune threshold on validation set\n",
        "val_result = evaluate(model, data, data.val_mask, threshold=0.5)\n",
        "best_thresh, best_val_f1_tuned = find_best_threshold(\n",
        "    val_result[\"probs\"], val_result[\"labels\"]\n",
        ")\n",
        "print(f\"\\n[threshold] Best threshold on val set: {best_thresh:.2f} \"\n",
        "      f\"(val F1 = {best_val_f1_tuned:.4f})\")\n",
        "\n",
        "# ── Final evaluation on TEST set\n",
        "test_result = evaluate(model, data, data.test_mask, threshold=best_thresh)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 55)\n",
        "print(\"  FINAL TEST SET RESULTS\")\n",
        "print(\"=\" * 55)\n",
        "print(classification_report(\n",
        "    test_result[\"labels\"], test_result[\"preds\"],\n",
        "    target_names=[\"Normal\", \"Fraud\"], digits=4\n",
        "))\n",
        "print(f\"  F1  (fraud): {test_result[\"f1\"]:.4f}\")\n",
        "print(f\"  ROC-AUC    : {test_result[\"auc\"]:.4f}\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "plot_confusion_matrix(test_result[\"labels\"], test_result[\"preds\"])\n",
        "plot_roc_curve(test_result[\"labels\"], test_result[\"probs\"],\n",
        "               test_result[\"auc\"])\n",
        "\n",
        "# ── Save model\n",
        "torch.save({\n",
        "    \"model_state\": best_state,\n",
        "    \"threshold\":   best_thresh,\n",
        "    \"num_features\": data.num_features,\n",
        "    \"hidden\":       hidden,\n",
        "    \"use_gat\":      use_gat,\n",
        "}, \"outputs/fraud_model.pth\")\n",
        "print(\"[train] Model saved → outputs/fraud_model.pth\")\n"
      ],
      "metadata": {
        "id": "unVg1uM9LYUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e400c6-2a51-4ecc-eec2-201433694946"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[config] use_gat=False, hidden=64, lr=0.001, epochs=100, patience=20\n",
            "[train] Using ImprovedGraphSAGE | features=12 | hidden=64\n",
            "Epoch 010 | Loss: 0.0070 | Val F1: 0.5168 | LR: 0.00100\n",
            "Epoch 020 | Loss: 0.0049 | Val F1: 0.6067 | LR: 0.00100\n",
            "Epoch 030 | Loss: 0.0041 | Val F1: 0.6413 | LR: 0.00100\n",
            "Epoch 040 | Loss: 0.0038 | Val F1: 0.6577 | LR: 0.00100\n",
            "Epoch 050 | Loss: 0.0035 | Val F1: 0.6796 | LR: 0.00100\n",
            "Epoch 060 | Loss: 0.0033 | Val F1: 0.6873 | LR: 0.00100\n",
            "Epoch 070 | Loss: 0.0031 | Val F1: 0.6917 | LR: 0.00100\n",
            "Epoch 080 | Loss: 0.0030 | Val F1: 0.6974 | LR: 0.00100\n",
            "Epoch 090 | Loss: 0.0029 | Val F1: 0.6982 | LR: 0.00100\n",
            "Epoch 100 | Loss: 0.0029 | Val F1: 0.6983 | LR: 0.00100\n",
            "[train] Restored best model from epoch 99\n",
            "[plot] Saved outputs/loss_f1_curve.png\n",
            "\n",
            "[threshold] Best threshold on val set: 0.45 (val F1 = 0.7020)\n",
            "\n",
            "=======================================================\n",
            "  FINAL TEST SET RESULTS\n",
            "=======================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal     0.9930    0.9941    0.9935     73391\n",
            "       Fraud     0.7220    0.6878    0.7045      1643\n",
            "\n",
            "    accuracy                         0.9874     75034\n",
            "   macro avg     0.8575    0.8409    0.8490     75034\n",
            "weighted avg     0.9871    0.9874    0.9872     75034\n",
            "\n",
            "  F1  (fraud): 0.7045\n",
            "  ROC-AUC    : 0.9858\n",
            "=======================================================\n",
            "[plot] Saved outputs/confusion_matrix.png\n",
            "[plot] Saved outputs/roc_curve.png\n",
            "[train] Model saved → outputs/fraud_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "\n",
        "# PLOT HELPERS\n",
        "\n",
        "def plot_loss_curve(train_losses: list, val_f1s: list):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    ax1.plot(train_losses, color=\"steelblue\")\n",
        "    ax1.set_title(\"Training Loss (Focal)\")\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "    ax2.plot(val_f1s, color=\"darkorange\")\n",
        "    ax2.set_title(\"Validation F1 Score (Fraud)\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax2.set_ylabel(\"F1\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"outputs/loss_f1_curve.png\", dpi=150)\n",
        "    plt.show()\n",
        "    print(\"[plot] Saved outputs/loss_f1_curve.png\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(labels: np.ndarray, preds: np.ndarray):\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"Normal\", \"Fraud\"],\n",
        "                yticklabels=[\"Normal\", \"Fraud\"])\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.title(\"Confusion Matrix — Test Set\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.savefig(\"outputs/confusion_matrix.png\", dpi=150)\n",
        "    plt.close()\n",
        "    print(\"[plot] Saved outputs/confusion_matrix.png\")\n",
        "\n",
        "\n",
        "def plot_roc_curve(labels: np.ndarray, probs: np.ndarray, auc_score: float):\n",
        "    fpr, tpr, _ = roc_curve(labels, probs)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, color=\"crimson\",\n",
        "             label=f\"ROC Curve (AUC = {auc_score:.4f})\")\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", linewidth=0.8)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve — Test Set\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"outputs/roc_curve.png\", dpi=150)\n",
        "    plt.close()\n",
        "    print(\"[plot] Saved outputs/roc_curve.png\")"
      ],
      "metadata": {
        "id": "FdrUCbZP0c7c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGrtu30eMD4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xy-sCeWNI7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}